{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "boston = pd.read_csv('Data_Set/housing.csv')\n",
    "feature_names = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat', 'medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with high correlation to the housing prices:\n",
      "crim\n",
      "zn\n",
      "indus\n",
      "nox\n",
      "rm\n",
      "age\n",
      "rad\n",
      "tax\n",
      "ptratio\n",
      "black\n",
      "lstat\n"
     ]
    }
   ],
   "source": [
    "# data cleaning, analysing and removing noise from our model using correlation matrix\n",
    "\n",
    "boston_frame = pd.DataFrame(boston, columns = feature_names)\n",
    "correlation_matirx = boston_frame.corr()\n",
    "\n",
    "# sourceFile = open('Correlation_Matrix.txt', 'w')\n",
    "# print(correlation_matirx, file = sourceFile)\n",
    "# sourceFile.close()\n",
    "\n",
    "correlation_matirx = np.array(correlation_matirx, dtype = 'float32')\n",
    "\n",
    "print(\"Features with high correlation to the housing prices:\")\n",
    "irrelevant_features = []\n",
    "\n",
    "for i in range(len(feature_names) - 1):\n",
    "    if(abs(correlation_matirx[13][i]) > 0.3):\n",
    "        print(feature_names[i])\n",
    "    \n",
    "    else:\n",
    "        irrelevant_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into two parts for training and testing randomly in a ratio of 80:20\n",
    "\n",
    "boston_data = np.array(boston_frame, dtype = 'float32')\n",
    "\n",
    "boston_data = np.delete(boston_data, (irrelevant_features), 1)\n",
    "features = boston_data[:, :-1]\n",
    "prices = boston_data[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, prices, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# m = number of training examples, n = number of features\n",
    "m = len(y_train)\n",
    "n = 13 - len(irrelevant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the data through feature scaling\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - x.mean(axis = 0)) / x.std(axis = 0)\n",
    "\n",
    "xo = x_test\n",
    "yo = y_test\n",
    "x_train = normalize(x_train)\n",
    "y_train = normalize(y_train)\n",
    "x_test = normalize(x_test)\n",
    "y_test = normalize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function and gradient descent functions\n",
    "\n",
    "def error(num, theta, x, y):\n",
    "    cost = 0\n",
    "\n",
    "    for i in range(num):\n",
    "        temp = 0\n",
    "        for j in range(n + 1):\n",
    "            if j == 0:\n",
    "                temp += theta[j]\n",
    "            else:\n",
    "                temp += (theta[j] * x[i][j - 1])\n",
    "\n",
    "        cost += ((temp - y[i]) ** 2)\n",
    "\n",
    "    return cost / (2 * m)\n",
    "\n",
    "def gradient_descent(alpha, theta, x, y):\n",
    "    temp = np.zeros(n + 1)\n",
    "\n",
    "    for i in range(m):\n",
    "        derivation = 0\n",
    "        for j in range(n + 1):\n",
    "            if j == 0:\n",
    "                derivation += theta[j]\n",
    "            else:\n",
    "                derivation += (theta[j] * x[i][j - 1])\n",
    "\n",
    "        derivation = (derivation - y[i])\n",
    "\n",
    "        for j in range(n + 1):\n",
    "            if j == 0:\n",
    "                temp[j] += derivation\n",
    "            else:\n",
    "                temp[j] += (derivation * x[i][j - 1])\n",
    "\n",
    "    temp = alpha * temp / m\n",
    "    theta -= temp\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9758413446782757\n",
      "1.736736240875559\n",
      "0.8307602809651498\n",
      "0.4587522675805239\n",
      "0.3020856662400888\n",
      "0.2332643203278807\n",
      "0.20097369697148873\n",
      "0.1843630544951446\n",
      "0.1748263580313563\n",
      "0.16871994806040622\n",
      "0.16443816483040213\n",
      "0.16123037620780273\n",
      "0.1587168474101369\n",
      "0.15668693256565988\n",
      "0.15501251129406116\n",
      "0.15360923888945974\n",
      "0.15241813632065712\n",
      "0.15139616162043046\n",
      "0.15051096088631516\n",
      "0.14973770059962796\n",
      "0.14905702042808094\n",
      "0.1484536387353872\n",
      "0.14791536595271165\n",
      "0.147432387539793\n",
      "0.14699673275134664\n",
      "0.14660187537631242\n",
      "0.1462424302673479\n",
      "0.1459139205205207\n",
      "0.14561259740996646\n",
      "0.14533530010887744\n",
      "0.14507934566842573\n",
      "0.14484244217675965\n",
      "0.1446226197926038\n",
      "0.1444181756456004\n",
      "0.1442276295551246\n",
      "0.14404968823499198\n",
      "0.14388321618921468\n",
      "0.14372721191063187\n",
      "0.14358078830358664\n",
      "0.1434431564883737\n",
      "0.1433136123269333\n",
      "0.1431915251495562\n",
      "0.14307632827106173\n",
      "0.1429675109695094\n",
      "0.1428646116665511\n",
      "0.14276721210032245\n",
      "0.1426749323225089\n",
      "0.1425874263833956\n",
      "0.14250437859420578\n",
      "0.14242550027632211\n",
      "0.14235052692318803\n",
      "0.14227921571367863\n",
      "0.14221134332619867\n",
      "0.14214670401122276\n",
      "0.14208510788687184\n",
      "0.14202637942773236\n",
      "0.14197035612171854\n",
      "0.14191688727357332\n",
      "0.14186583293674404\n",
      "0.14181706295796778\n",
      "0.14177045612109884\n",
      "0.14172589937852917\n",
      "0.14168328716010933\n",
      "0.14164252075078337\n",
      "0.14160350772927147\n",
      "0.14156616146108486\n",
      "0.1415304006399838\n",
      "0.14149614887269\n",
      "0.14146333430228358\n",
      "0.14143188926623693\n",
      "0.14140174998551283\n",
      "0.14137285628154314\n",
      "0.1413451513182735\n",
      "0.14131858136675934\n",
      "0.14129309559007394\n"
     ]
    }
   ],
   "source": [
    "theta = []\n",
    "alpha = 0.3\n",
    "iterations = 75\n",
    "\n",
    "for _ in range(n + 1):\n",
    "    theta.append(random.random())\n",
    "\n",
    "for _ in range(iterations):\n",
    "    print(error(m, theta, x_train, y_train))\n",
    "    theta = gradient_descent(alpha, theta, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.84612431348353\n",
      "24.414518284557783 23.6\n",
      "25.553710248054998 32.4\n",
      "-18.821770542017862 13.6\n",
      "18.678649703042744 22.8\n",
      "-12.989093681345969 16.1\n",
      "9.858631550327209 20.0\n",
      "18.80175843882489 17.8\n",
      "4.13623486294235 14.0\n",
      "-9.874856221299826 19.6\n",
      "12.683138993370275 16.8\n",
      "24.189726413377038 21.5\n",
      "18.590147526245982 18.9\n",
      "-63.237389679284526 7.0\n",
      "9.934712645598474 21.2\n",
      "22.178218011694735 18.5\n",
      "-13.44312147743263 29.8\n",
      "30.3773806869227 18.8\n",
      "-20.705958837555812 10.2\n",
      "24.331910465134033 50.0\n",
      "-11.720060200732828 14.1\n",
      "26.490656347006524 25.2\n",
      "23.919342711423784 29.1\n",
      "12.64748803925596 12.7\n",
      "23.795667130574575 22.4\n",
      "-20.896614303657596 14.2\n",
      "-17.906508660391633 13.8\n",
      "11.19082441939664 20.3\n",
      "-63.052280503155295 14.9\n",
      "22.83225625513593 21.7\n",
      "12.060142143132921 18.3\n",
      "22.301135071644044 23.1\n",
      "23.533603755160073 23.8\n",
      "-10.323612178401593 15.0\n",
      "-10.640868113358287 20.8\n",
      "-21.50392037139425 19.1\n",
      "-4.095602871861585 19.4\n",
      "29.48613283737272 34.7\n",
      "27.702459352742398 19.5\n",
      "20.105783165916925 24.4\n",
      "16.020702635392706 23.4\n",
      "9.22956824467186 19.7\n",
      "29.95586908835614 28.2\n",
      "26.388176680940372 50.0\n",
      "13.52825137960571 17.4\n",
      "24.545391440627057 22.6\n",
      "-11.726446223949631 15.1\n",
      "14.230370121428777 13.1\n",
      "17.309282218539867 24.2\n",
      "-11.559753309719362 19.9\n",
      "23.760324937291625 24.0\n",
      "21.263409270666397 18.9\n",
      "30.06516791980861 35.4\n",
      "18.99655209654998 15.2\n",
      "14.939450772283966 26.5\n",
      "27.418138982471774 43.5\n",
      "-12.431185997603254 21.2\n",
      "-10.849830577896231 18.4\n",
      "23.984004327063758 28.5\n",
      "25.894767341597984 23.9\n",
      "14.113626513053891 18.5\n",
      "21.478507412689574 25.0\n",
      "24.635467718547957 35.4\n",
      "19.66259599154029 31.5\n",
      "3.7304858656941864 20.2\n",
      "4.851316937379251 24.1\n",
      "21.25255046458316 20.0\n",
      "-11.787308390716106 13.1\n",
      "21.626181149452623 24.8\n",
      "22.35155521999927 30.8\n",
      "-62.97741435896086 12.7\n",
      "24.502244726279464 20.0\n",
      "-9.131625330804654 23.7\n",
      "-34.990932141508154 10.8\n",
      "9.870602415030561 20.6\n",
      "10.26217341351505 20.8\n",
      "-19.37150352874518 5.0\n",
      "13.732973415657133 20.1\n",
      "26.324403482596793 48.5\n",
      "-13.291865996566976 10.9\n",
      "-27.46945925434897 7.0\n",
      "15.109334316303535 20.9\n",
      "-25.889728793067825 17.2\n",
      "13.6935212868242 20.9\n",
      "-15.499130293056899 9.7\n",
      "22.732901562460558 19.4\n",
      "18.460601861006786 29.0\n",
      "-29.55715329173249 16.4\n",
      "23.11349131778595 25.0\n",
      "23.341383876270232 25.0\n",
      "9.201288138637535 17.1\n",
      "21.010717555266943 23.2\n",
      "-52.7454185008444 10.4\n",
      "10.339910838854987 19.6\n",
      "10.263348587030741 17.2\n",
      "-14.133693556442726 27.5\n",
      "9.425549763578555 23.0\n",
      "-12.158590843473782 50.0\n",
      "-67.63155015474999 17.9\n",
      "-60.641352953619496 9.6\n",
      "-60.3505930342449 17.2\n",
      "24.131381131086073 22.5\n",
      "10.310034544476137 21.4\n"
     ]
    }
   ],
   "source": [
    "print(error(len(y_test), theta, xo, yo))\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    price = 0\n",
    "    for j in range(n + 1):\n",
    "        if j == 0:\n",
    "            price += theta[j]\n",
    "        else:\n",
    "            price += (theta[j] * xo[i][j - 1])\n",
    "\n",
    "    print(price, yo[i])\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# y = y_train\n",
    "# x = x_train[:, 0]\n",
    "\n",
    "# plt.plot(x, y, 'ro')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2f2c10e8b0c6806d9d04e8d3a17761b4c554a55a9bbe8b591472136559041bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
