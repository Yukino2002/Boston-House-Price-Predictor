{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "boston = pd.read_csv('Data_Set/housing.csv')\n",
    "feature_names = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat', 'medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with high correlation to the housing prices:\n",
      "rm\n",
      "ptratio\n",
      "lstat\n"
     ]
    }
   ],
   "source": [
    "# data cleaning, analysing and removing noise from our model using correlation matrix\n",
    "\n",
    "boston_frame = pd.DataFrame(boston, columns = feature_names)\n",
    "correlation_matirx = boston_frame.corr()\n",
    "\n",
    "# sourceFile = open('Correlation_Matrix.txt', 'w')\n",
    "# print(correlation_matirx, file = sourceFile)\n",
    "# sourceFile.close()\n",
    "\n",
    "correlation_matirx = np.array(correlation_matirx, dtype = 'float32')\n",
    "\n",
    "print(\"Features with high correlation to the housing prices:\")\n",
    "irrelevant_features = []\n",
    "\n",
    "for i in range(len(feature_names) - 1):\n",
    "    if(abs(correlation_matirx[13][i]) > 0.5):\n",
    "        print(feature_names[i])\n",
    "    \n",
    "    else:\n",
    "        irrelevant_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into two parts for training and testing randomly in a ratio of 80:20\n",
    "\n",
    "boston_data = np.array(boston_frame, dtype = 'float32')\n",
    "censored_data = []\n",
    "boston_data = np.delete(boston_data, (irrelevant_features), 1)\n",
    "for i in range(len(boston_data) - 13):\n",
    "    if boston_data[i, -1] == 50:\n",
    "        censored_data.append(i)\n",
    "\n",
    "boston_data = np.delete(boston_data, (censored_data), 0)\n",
    "features = boston_data[:, :-1]\n",
    "prices = boston_data[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, prices, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# m = number of training examples, n = number of features\n",
    "m = len(y_train)\n",
    "n = 13 - len(irrelevant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the data through feature scaling\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - x.mean(axis = 0)) / x.std(axis = 0)\n",
    "\n",
    "x_train = normalize(x_train)\n",
    "y_train = normalize(y_train)\n",
    "x_test = normalize(x_test)\n",
    "y_test = normalize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function and gradient descent functions\n",
    "\n",
    "def error(num, theta, x, y):\n",
    "    cost = 0\n",
    "\n",
    "    for i in range(num):\n",
    "        temp = 0\n",
    "        for j in range(n + 1):\n",
    "            if j == 0:\n",
    "                temp += theta[j]\n",
    "            else:\n",
    "                temp += (theta[j] * x[i][j - 1])\n",
    "\n",
    "        cost += ((temp - y[i]) ** 2)\n",
    "\n",
    "    return cost / (2 * num)\n",
    "\n",
    "def gradient_descent(alpha, theta, x, y):\n",
    "    temp = np.zeros(n + 1)\n",
    "\n",
    "    for i in range(m):\n",
    "        derivation = 0\n",
    "        for j in range(n + 1):\n",
    "            if j == 0:\n",
    "                derivation += theta[j]\n",
    "            else:\n",
    "                derivation += (theta[j] * x[i][j - 1])\n",
    "\n",
    "        derivation = (derivation - y[i])\n",
    "\n",
    "        for j in range(n + 1):\n",
    "            if j == 0:\n",
    "                temp[j] += derivation\n",
    "            else:\n",
    "                temp[j] += (derivation * x[i][j - 1])\n",
    "\n",
    "    temp = alpha * temp / m\n",
    "    theta -= temp\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = []\n",
    "alpha = 0.3\n",
    "iterations = 75\n",
    "\n",
    "for _ in range(n + 1):\n",
    "    theta.append(random.random())\n",
    "\n",
    "for _ in range(iterations):\n",
    "    theta = gradient_descent(alpha, theta, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15898271162932892\n"
     ]
    }
   ],
   "source": [
    "print(error(len(y_test), theta, x_test, y_test))\n",
    "\n",
    "# for i in range(len(y_test)):\n",
    "#     price = 0\n",
    "#     for j in range(n + 1):\n",
    "#         if j == 0:\n",
    "#             price += theta[j]\n",
    "#         else:\n",
    "#             price += (theta[j] * x_test[i][j - 1])\n",
    "\n",
    "#     print(price, y_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6356599879645601 [-0.63566464]\n",
      "0.44447416560431957 [0.44447857]\n",
      "-0.09860545354892092 [-0.09864734]\n",
      "-1.3099076870999378 [-1.3099121]\n",
      "-1.0496169037699374 [-1.0496416]\n",
      "-0.26044003594412174 [-0.26040882]\n",
      "-1.1715339320966844 [-1.171545]\n",
      "1.7521336566556278 [1.7520962]\n",
      "-0.5058863035144688 [-0.5058632]\n",
      "0.9962559261605248 [0.9962549]\n",
      "0.2012073350138418 [0.20119178]\n",
      "-0.4686979646089634 [-0.4687006]\n",
      "-1.6716343445527553 [-1.6717057]\n",
      "-1.0997136955100826 [-1.0997211]\n",
      "-0.538470203756257 [-0.5385314]\n",
      "0.5500736130950168 [0.5500904]\n",
      "-0.3653688407669642 [-0.36539233]\n",
      "-0.3306816883988337 [-0.33069518]\n",
      "0.04734486876367605 [0.04729325]\n",
      "-0.05766540885769045 [-0.05767908]\n",
      "0.143483222885734 [0.14348437]\n",
      "0.17328403295019898 [0.1732836]\n",
      "-0.9610321386177936 [-0.9610481]\n",
      "1.3603754460092536 [1.3603568]\n",
      "0.19581897353113925 [0.19581938]\n",
      "0.22416045058013442 [0.22417471]\n",
      "0.4779436780509252 [0.47792917]\n",
      "1.2876126039629172 [1.2876201]\n",
      "1.6405152558565685 [1.6405044]\n",
      "-0.8599405035386397 [-0.8599439]\n",
      "0.4596109787295855 [0.45960987]\n",
      "-1.2620428718194847 [-1.2620729]\n",
      "0.6080978794471086 [0.6081217]\n",
      "0.4133208772138064 [0.41334915]\n",
      "-0.9001808738241237 [-0.90017366]\n",
      "0.3935454455362462 [0.39356712]\n",
      "1.3222742905443778 [1.3222817]\n",
      "0.45519458447879035 [0.45519477]\n",
      "1.5030331000064168 [1.5030082]\n",
      "1.3431085319477187 [1.3431021]\n",
      "-0.4011205443535911 [-0.40118822]\n",
      "-0.19040335199310232 [-0.19046004]\n",
      "-0.8680436888116949 [-0.86807853]\n",
      "0.1830376811494268 [0.18304081]\n",
      "-0.3158550884385379 [-0.31582555]\n",
      "1.0016297709220792 [1.0016458]\n",
      "-0.6101325093057325 [-0.6100856]\n",
      "-0.28703848310494773 [-0.28705353]\n",
      "-0.1817174290809089 [-0.18171346]\n",
      "-0.30588808434974857 [-0.3058718]\n",
      "-0.34877969206384724 [-0.34881464]\n",
      "0.9438285068601365 [0.94384456]\n",
      "0.8931285122014927 [0.89314616]\n",
      "-0.0730439613045295 [-0.07301432]\n",
      "0.4982421055093425 [0.49822688]\n",
      "0.4183561506940783 [0.41839504]\n",
      "-0.47432493248427643 [-0.47434184]\n",
      "0.604938791451767 [0.60496545]\n",
      "-0.03123016751051777 [-0.03120003]\n",
      "-0.9506687381079996 [-0.9506924]\n",
      "0.20173432752570974 [0.20173424]\n",
      "-0.35963557570277627 [-0.35964814]\n",
      "0.5017874469652824 [0.50177693]\n",
      "0.20332668401066778 [0.20335855]\n",
      "0.844146642608053 [0.84414256]\n",
      "2.148644692340067 [2.1486073]\n",
      "0.6154760711747941 [0.6154809]\n",
      "0.6429248332742399 [0.6429301]\n",
      "-1.2242130052799285 [-1.2241883]\n",
      "-0.22839302050123333 [-0.22835758]\n",
      "-0.3106943581711958 [-0.31072482]\n",
      "-0.21271710983560735 [-0.21270777]\n",
      "-0.09220096074219944 [-0.09218471]\n",
      "0.08980832056829055 [0.08981632]\n",
      "-0.5832090706784611 [-0.5832165]\n",
      "0.14187162121545036 [0.14190371]\n",
      "0.18678748550674573 [0.1868105]\n",
      "-0.10514704333803335 [-0.10513848]\n",
      "0.5102584594059609 [0.5102804]\n",
      "-0.15647429530836257 [-0.15647173]\n",
      "0.45792114635458525 [0.45794013]\n",
      "0.9193797390531264 [0.91936946]\n",
      "-2.045629820546026 [-2.0455692]\n",
      "-1.0086908738646985 [-1.0086843]\n",
      "0.28117413248402473 [0.28119203]\n",
      "0.8575908016741216 [0.8576028]\n",
      "0.008633199463163453 [0.00864229]\n",
      "0.3985736199476373 [0.39858633]\n",
      "-0.7005126599088659 [-0.7005677]\n",
      "-0.1732116848445272 [-0.17316978]\n",
      "0.19369459838224576 [0.1937024]\n",
      "-0.5423145306435053 [-0.5423099]\n",
      "-0.42130978680862907 [-0.4212744]\n",
      "0.341461378991709 [0.34148607]\n",
      "-1.6623257038185846 [-1.6623185]\n",
      "0.866659207921292 [0.8666773]\n",
      "0.17589759512867317 [0.17589524]\n",
      "-2.7118380682251875 [-2.7118528]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    price = 0\n",
    "    for j in range(n + 1):\n",
    "        if j == 0:\n",
    "            price += theta[j]\n",
    "        else:\n",
    "            price += (theta[j] * x_test[i][j - 1])\n",
    "    \n",
    "    print(price, model.predict(x_test[i].reshape(1, -1)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2f2c10e8b0c6806d9d04e8d3a17761b4c554a55a9bbe8b591472136559041bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
