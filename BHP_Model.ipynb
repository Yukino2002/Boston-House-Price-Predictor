{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "boston = pd.read_csv('Data_Set/housing.csv')\n",
    "feature_names = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat', 'medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with high correlation to the housing prices:\n",
      "crim\n",
      "zn\n",
      "indus\n",
      "nox\n",
      "rm\n",
      "age\n",
      "rad\n",
      "tax\n",
      "ptratio\n",
      "black\n",
      "lstat\n"
     ]
    }
   ],
   "source": [
    "# data cleaning, analysing and removing noise from our model using correlation matrix\n",
    "\n",
    "boston_frame = pd.DataFrame(boston, columns = feature_names)\n",
    "correlation_matirx = boston_frame.corr()\n",
    "\n",
    "# sourceFile = open('Correlation_Matrix.txt', 'w')\n",
    "# print(correlation_matirx, file = sourceFile)\n",
    "# sourceFile.close()\n",
    "\n",
    "correlation_matirx = np.array(correlation_matirx, dtype = 'float32')\n",
    "\n",
    "print(\"Features with high correlation to the housing prices:\")\n",
    "irrelevant_features = []\n",
    "\n",
    "for i in range(len(feature_names) - 1):\n",
    "    if(abs(correlation_matirx[13][i]) > 0.3):\n",
    "        print(feature_names[i])\n",
    "    \n",
    "    else:\n",
    "        irrelevant_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into two parts for training and testing randomly in a ratio of 80:20\n",
    "\n",
    "boston_data = np.array(boston_frame, dtype = 'float32')\n",
    "censored_data = []\n",
    "boston_data = np.delete(boston_data, (irrelevant_features), 1)\n",
    "for i in range(len(boston_data) - 13):\n",
    "    if boston_data[i, -1] == 50:\n",
    "        censored_data.append(i)\n",
    "\n",
    "boston_data = np.delete(boston_data, (censored_data), 0)\n",
    "features = boston_data[:, :-1]\n",
    "prices = boston_data[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, prices, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# m = number of training examples, n = number of features\n",
    "m = len(y_train)\n",
    "n = 13 - len(irrelevant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the data through feature scaling\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - x.mean(axis = 0)) / x.std(axis = 0)\n",
    "\n",
    "x_train = normalize(x_train)\n",
    "y_train = normalize(y_train)\n",
    "x_test = normalize(x_test)\n",
    "y_test = normalize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function and gradient descent functions\n",
    "\n",
    "def error(num, theta, x, y):\n",
    "    cost = 0\n",
    "\n",
    "    for i in range(num):\n",
    "        temp = 0\n",
    "        for j in range(n + 1):\n",
    "            if j == 0:\n",
    "                temp += theta[j]\n",
    "            else:\n",
    "                temp += (theta[j] * x[i][j - 1])\n",
    "\n",
    "        cost += ((temp - y[i]) ** 2)\n",
    "\n",
    "    return cost / (2 * num)\n",
    "\n",
    "def gradient_descent(alpha, theta, x, y):\n",
    "    temp = np.zeros(n + 1)\n",
    "\n",
    "    for i in range(m):\n",
    "        derivation = 0\n",
    "        for j in range(n + 1):\n",
    "            if j == 0:\n",
    "                derivation += theta[j]\n",
    "            else:\n",
    "                derivation += (theta[j] * x[i][j - 1])\n",
    "\n",
    "        derivation = (derivation - y[i])\n",
    "\n",
    "        for j in range(n + 1):\n",
    "            if j == 0:\n",
    "                temp[j] += derivation\n",
    "            else:\n",
    "                temp[j] += (derivation * x[i][j - 1])\n",
    "\n",
    "    temp = alpha * temp / m\n",
    "    theta -= temp\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = []\n",
    "alpha = 0.3\n",
    "iterations = 75\n",
    "\n",
    "for _ in range(n + 1):\n",
    "    theta.append(random.random())\n",
    "\n",
    "for _ in range(iterations):\n",
    "    theta = gradient_descent(alpha, theta, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1316606530430089\n"
     ]
    }
   ],
   "source": [
    "print(error(len(y_test), theta, x_test, y_test))\n",
    "\n",
    "# for i in range(len(y_test)):\n",
    "#     price = 0\n",
    "#     for j in range(n + 1):\n",
    "#         if j == 0:\n",
    "#             price += theta[j]\n",
    "#         else:\n",
    "#             price += (theta[j] * x_test[i][j - 1])\n",
    "\n",
    "#     print(price, y_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6099226578420438 [-0.5938799]\n",
      "0.5776160804596094 [0.576762]\n",
      "-0.421707482761 [-0.41511276]\n",
      "-1.598543003227313 [-1.7042704]\n",
      "-1.1053001952356682 [-1.0970433]\n",
      "-0.12166278543171373 [-0.11081198]\n",
      "-0.9460023075043676 [-0.9531246]\n",
      "1.7811738676801618 [1.7846191]\n",
      "-0.4548049459029871 [-0.47842276]\n",
      "1.058234375636107 [1.0739869]\n",
      "0.3480510937475764 [0.36125675]\n",
      "-0.25919988350462103 [-0.15617746]\n",
      "-1.7338315527229187 [-1.7284436]\n",
      "-0.7765143553179716 [-0.74987984]\n",
      "-0.46512396028254643 [-0.45792988]\n",
      "0.5842740702307765 [0.5872382]\n",
      "-0.3877564129733784 [-0.37925404]\n",
      "-0.33679039580257053 [-0.32916752]\n",
      "-0.5318961583935556 [-0.56092006]\n",
      "0.1512159170827206 [0.19684586]\n",
      "0.1772563720317598 [0.16162187]\n",
      "0.3974917013352614 [0.41470048]\n",
      "-0.9732100827238999 [-0.9692043]\n",
      "1.436140159760622 [1.4779028]\n",
      "0.21500806288570112 [0.2018584]\n",
      "0.22212588211692508 [0.20608027]\n",
      "0.24311646446774626 [0.23288088]\n",
      "1.289924918579858 [1.3159133]\n",
      "1.7342860114144962 [1.7683858]\n",
      "-0.7684687068940976 [-0.7526684]\n",
      "0.42981202072230085 [0.39074516]\n",
      "-0.9183978983495921 [-0.8142278]\n",
      "0.6369738092112549 [0.6353596]\n",
      "0.5206991278814923 [0.5389241]\n",
      "-0.745632833109372 [-0.75240606]\n",
      "0.4323311497016197 [0.4362588]\n",
      "1.2113159025314675 [1.1723692]\n",
      "0.5491800287769785 [0.5621383]\n",
      "1.5611761776054012 [1.573816]\n",
      "1.1576702732194315 [1.1118833]\n",
      "-0.6362998578741015 [-0.63523513]\n",
      "-0.306346844567433 [-0.29362935]\n",
      "-1.056101188805147 [-1.0389671]\n",
      "-0.10720553702618174 [-0.11487812]\n",
      "-0.21647887082476366 [-0.23578538]\n",
      "0.8855510907263715 [0.8653761]\n",
      "-0.6419296952837197 [-0.65477705]\n",
      "-0.3807708339052247 [-0.37233892]\n",
      "-0.13726674624967178 [-0.16299635]\n",
      "-0.26928506154442095 [-0.29475388]\n",
      "-0.31481441961394774 [-0.30835915]\n",
      "0.9326431006502677 [0.9502267]\n",
      "0.9208281376953482 [0.914952]\n",
      "-0.008486426808936492 [-0.00345121]\n",
      "0.017164700414336764 [0.00348076]\n",
      "0.43688963283009463 [0.4423537]\n",
      "-0.40610428816210264 [-0.3883993]\n",
      "0.6274817970567899 [0.67698705]\n",
      "0.14258726830431095 [0.1657055]\n",
      "-0.9510219408290368 [-0.9563073]\n",
      "0.21119562665805827 [0.2010028]\n",
      "-0.32197232368505746 [-0.31169105]\n",
      "0.684541517272681 [0.7124127]\n",
      "0.2796952678644659 [0.2852149]\n",
      "0.7586553085599892 [0.6997689]\n",
      "2.2100580254844835 [2.2414906]\n",
      "0.6643678347677358 [0.6417724]\n",
      "0.7480973056947035 [0.77514523]\n",
      "-1.433682324069894 [-1.41654]\n",
      "-0.1875017447542661 [-0.16452883]\n",
      "-0.6744472922465334 [-0.67155516]\n",
      "-0.1714763826192649 [-0.20422801]\n",
      "-0.058738135096480494 [-0.10297882]\n",
      "0.10511193912640493 [0.12169491]\n",
      "-0.9179390850362 [-1.0269207]\n",
      "0.12548113872671018 [0.10997351]\n",
      "0.22760752740511114 [0.23079284]\n",
      "0.05462317581844261 [0.05888678]\n",
      "0.5692682260293782 [0.5717776]\n",
      "-0.26482947111364874 [-0.28277218]\n",
      "0.5258805118339805 [0.5299402]\n",
      "1.0059427715480331 [1.0233727]\n",
      "-2.0228360940576042 [-2.0000591]\n",
      "-0.8603390893780224 [-0.88315994]\n",
      "0.2202136893706757 [0.18409221]\n",
      "0.7048100322537147 [0.6517677]\n",
      "0.18998601376930063 [0.19103223]\n",
      "0.3722847740221248 [0.3552249]\n",
      "-0.9219708505627026 [-0.91731155]\n",
      "-0.14612380613748405 [-0.15828374]\n",
      "0.3196485379652367 [0.36074534]\n",
      "-0.5505407163869444 [-0.538717]\n",
      "-0.3521988672549909 [-0.3620649]\n",
      "0.25605176795402185 [0.17938845]\n",
      "-1.5142843407989226 [-1.4967172]\n",
      "0.7869468200856842 [0.7713058]\n",
      "0.2386663130975606 [0.24962194]\n",
      "-2.951666390106744 [-2.9467783]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    price = 0\n",
    "    for j in range(n + 1):\n",
    "        if j == 0:\n",
    "            price += theta[j]\n",
    "        else:\n",
    "            price += (theta[j] * x_test[i][j - 1])\n",
    "    \n",
    "    print(price, model.predict(x_test[i].reshape(1, -1)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2f2c10e8b0c6806d9d04e8d3a17761b4c554a55a9bbe8b591472136559041bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
