{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "boston = pd.read_csv('Data_Set/housing.csv')\n",
    "feature_names = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat', 'medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with high correlation to the housing prices:\n",
      "crim\n",
      "zn\n",
      "indus\n",
      "nox\n",
      "rm\n",
      "age\n",
      "rad\n",
      "tax\n",
      "ptratio\n",
      "black\n",
      "lstat\n"
     ]
    }
   ],
   "source": [
    "# data cleaning, analysing and removing noise from our model using correlation matrix\n",
    "\n",
    "boston_frame = pd.DataFrame(boston, columns = feature_names)\n",
    "correlation_matirx = boston_frame.corr()\n",
    "\n",
    "# sourceFile = open('Correlation_Matrix.txt', 'w')\n",
    "# print(correlation_matirx, file = sourceFile)\n",
    "# sourceFile.close()\n",
    "\n",
    "correlation_matirx = np.array(correlation_matirx, dtype = 'float32')\n",
    "\n",
    "print(\"Features with high correlation to the housing prices:\")\n",
    "irrelevant_features = []\n",
    "\n",
    "for i in range(len(feature_names) - 1):\n",
    "    if(abs(correlation_matirx[13][i]) > 0.3):\n",
    "        print(feature_names[i])\n",
    "    \n",
    "    else:\n",
    "        irrelevant_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into two parts for training and testing randomly in a ratio of 80:20\n",
    "\n",
    "boston_data = np.array(boston_frame, dtype = 'float32')\n",
    "\n",
    "boston_data = np.delete(boston_data, (irrelevant_features), 1)\n",
    "features = boston_data[:, :-1]\n",
    "prices = boston_data[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, prices, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# m = number of training examples, n = number of features\n",
    "m = len(y_train)\n",
    "n = 13 - len(irrelevant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the data through feature scaling\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - x.mean(axis = 0)) / x.std(axis = 0)\n",
    "\n",
    "xo = x_test\n",
    "yo = y_test\n",
    "x_train = normalize(x_train)\n",
    "y_train = normalize(y_train)\n",
    "x_test = normalize(x_test)\n",
    "y_test = normalize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function and gradient descent functions\n",
    "\n",
    "def error(num, theta, x, y):\n",
    "    cost = 0\n",
    "\n",
    "    for i in range(num):\n",
    "        temp = 0\n",
    "        for j in range(n + 1):\n",
    "            if j == 0:\n",
    "                temp += theta[j]\n",
    "            else:\n",
    "                temp += (theta[j] * x[i][j - 1])\n",
    "\n",
    "        cost += ((temp - y[i]) ** 2)\n",
    "\n",
    "    return cost / (2 * num)\n",
    "\n",
    "def gradient_descent(alpha, theta, x, y):\n",
    "    temp = np.zeros(n + 1)\n",
    "\n",
    "    for i in range(m):\n",
    "        derivation = 0\n",
    "        for j in range(n + 1):\n",
    "            if j == 0:\n",
    "                derivation += theta[j]\n",
    "            else:\n",
    "                derivation += (theta[j] * x[i][j - 1])\n",
    "\n",
    "        derivation = (derivation - y[i])\n",
    "\n",
    "        for j in range(n + 1):\n",
    "            if j == 0:\n",
    "                temp[j] += derivation\n",
    "            else:\n",
    "                temp[j] += (derivation * x[i][j - 1])\n",
    "\n",
    "    temp = alpha * temp / m\n",
    "    theta -= temp\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1582560694523565\n",
      "2.347295179094553\n",
      "1.1736837814088805\n",
      "0.6689226824347081\n",
      "0.44165035613117004\n",
      "0.33232404569605695\n",
      "0.27501638738852885\n",
      "0.24191101222916137\n",
      "0.2208975534769403\n",
      "0.2064591606217893\n",
      "0.19592430455517806\n",
      "0.18789890157098016\n",
      "0.18159401965863395\n",
      "0.17652721731972362\n",
      "0.17238333551390714\n",
      "0.16894556540296773\n",
      "0.16605887120599616\n",
      "0.1636091570305898\n",
      "0.16151060273468426\n",
      "0.15969753332207734\n",
      "0.15811896928144253\n",
      "0.15673485156579603\n",
      "0.1555133598691322\n",
      "0.15442896960958982\n",
      "0.15346102144826043\n",
      "0.15259265389979035\n",
      "0.15180999753294444\n",
      "0.15110156030857383\n",
      "0.15045775428637187\n",
      "0.14987052802205367\n",
      "0.1493330787508418\n",
      "0.14883962533737327\n",
      "0.14838522788511044\n",
      "0.14796564344569607\n",
      "0.14757720985716022\n",
      "0.1472167516469334\n",
      "0.1468815033530868\n",
      "0.14656904667938464\n",
      "0.14627725870165253\n",
      "0.14600426895260263\n",
      "0.14574842367871274\n",
      "0.1455082559217853\n",
      "0.14528246035572306\n",
      "0.145069872025304\n",
      "0.14486944830285645\n",
      "0.1446802535116323\n",
      "0.14450144576960228\n",
      "0.14433226569061247\n",
      "0.1441720266461419\n",
      "0.14402010634394358\n",
      "0.14387593952250965\n",
      "0.14373901159470784\n",
      "0.14360885310186666\n",
      "0.14348503486231268\n",
      "0.14336716371696573\n",
      "0.1432548787898792\n",
      "0.1431478481942277\n",
      "0.14304576612468525\n",
      "0.1429483502858525\n",
      "0.14285533961365032\n",
      "0.1427664922527062\n",
      "0.1426815837579005\n",
      "0.14260040549258263\n",
      "0.14252276319966803\n",
      "0.14244847572496397\n",
      "0.14237737387475508\n",
      "0.1423092993919995\n",
      "0.14224410403744522\n",
      "0.1421816487637051\n",
      "0.14212180297178822\n",
      "0.14206444384087832\n",
      "0.1420094557232518\n",
      "0.14195672959719896\n",
      "0.14190616257165936\n",
      "0.14185765743700704\n"
     ]
    }
   ],
   "source": [
    "theta = []\n",
    "alpha = 0.3\n",
    "iterations = 75\n",
    "\n",
    "for _ in range(n + 1):\n",
    "    theta.append(random.random())\n",
    "\n",
    "for _ in range(iterations):\n",
    "    print(error(m, theta, x_train, y_train))\n",
    "    theta = gradient_descent(alpha, theta, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1928442596714695\n",
      "34.86258598748316 23.6\n",
      "34.41561750098212 32.4\n",
      "6.514571179551217 13.6\n",
      "29.639951227602605 22.8\n",
      "10.166117149241035 16.1\n",
      "23.96689564331067 20.0\n",
      "29.540763925726328 17.8\n",
      "19.583034841106496 14.0\n",
      "13.269686473422253 19.6\n",
      "26.530364425288987 16.8\n",
      "33.79441932457152 21.5\n",
      "29.49019161070051 18.9\n",
      "-39.995820434149294 7.0\n",
      "24.108423797931895 21.2\n",
      "32.30136438922608 18.5\n",
      "9.770592398704917 29.8\n",
      "36.74343727437669 18.8\n",
      "2.476138755455173 10.2\n",
      "33.08741619019535 50.0\n",
      "11.427968505651938 14.1\n",
      "34.41269184165973 25.2\n",
      "32.792516781026265 29.1\n",
      "23.495367954846877 12.7\n",
      "33.51052686816699 22.4\n",
      "2.2395989330755697 14.2\n",
      "5.239782775746748 13.8\n",
      "25.407599281585675 20.3\n",
      "-39.932788035403455 14.9\n",
      "32.54993561014091 21.7\n",
      "25.9336016301257 18.3\n",
      "32.74802170316085 23.1\n",
      "33.7146098878456 23.8\n",
      "12.843990565378096 15.0\n",
      "12.474368196968497 20.8\n",
      "1.6443895768428654 19.1\n",
      "10.042760261581964 19.4\n",
      "38.09551201648908 34.7\n",
      "35.634516084265435 19.5\n",
      "29.91562146592546 24.4\n",
      "26.991630760999612 23.4\n",
      "23.1134708884318 19.7\n",
      "37.53065084732823 28.2\n",
      "33.91259830912915 50.0\n",
      "25.865156044377716 17.4\n",
      "34.209919819251894 22.6\n",
      "11.415952038748763 15.1\n",
      "25.063900583221123 13.1\n",
      "28.277979899247402 24.2\n",
      "11.615217143831982 19.9\n",
      "34.31463298460309 24.0\n",
      "32.16336071393996 18.9\n",
      "37.63032944762847 35.4\n",
      "29.84760256900932 15.2\n",
      "28.59053621171974 26.5\n",
      "36.67554190146027 43.5\n",
      "10.823884389811013 21.2\n",
      "12.281088448975485 18.4\n",
      "32.34422606967351 28.5\n",
      "34.73398547870796 23.9\n",
      "25.667721151682088 18.5\n",
      "31.377809929622572 25.0\n",
      "32.27924286816354 35.4\n",
      "30.56388490155395 31.5\n",
      "14.71340897856696 20.2\n",
      "19.377607913850973 24.1\n",
      "30.960562849785113 20.0\n",
      "11.35665679034167 13.1\n",
      "31.57806689523016 24.8\n",
      "31.06696783828489 30.8\n",
      "-39.852769491626404 12.7\n",
      "32.85865089125723 20.0\n",
      "14.053032693676833 23.7\n",
      "-11.83259356246876 10.8\n",
      "21.538628038123058 20.6\n",
      "24.45410113884548 20.8\n",
      "3.8751119207541453 5.0\n",
      "27.337080368214313 20.1\n",
      "33.84697243167317 48.5\n",
      "9.88040587077426 10.9\n",
      "-2.1232523674221184 7.0\n",
      "27.447328167080393 20.9\n",
      "-2.7341505516350626 17.2\n",
      "24.755177906760114 20.9\n",
      "7.675429612905102 9.7\n",
      "33.43317019087671 19.4\n",
      "29.234664101229612 29.0\n",
      "-6.41339488357029 16.4\n",
      "33.32905664439686 25.0\n",
      "32.77309189122357 25.0\n",
      "24.609682680208245 17.1\n",
      "31.57194740970275 23.2\n",
      "-29.53992270919474 10.4\n",
      "25.746072157719425 19.6\n",
      "22.921132234721565 17.2\n",
      "8.990333162799983 27.5\n",
      "24.82538636113761 23.0\n",
      "10.95828869762715 50.0\n",
      "-44.470694696748296 17.9\n",
      "-37.507534610719865 9.6\n",
      "-37.22824312853527 17.2\n",
      "32.98656912353496 22.5\n",
      "24.50095767225139 21.4\n"
     ]
    }
   ],
   "source": [
    "print(error(len(y_test), theta, x_test, y_test))\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    price = 0\n",
    "    for j in range(n + 1):\n",
    "        if j == 0:\n",
    "            price += theta[j]\n",
    "        else:\n",
    "            price += (theta[j] * xo[i][j - 1])\n",
    "\n",
    "    print(price, yo[i])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2f2c10e8b0c6806d9d04e8d3a17761b4c554a55a9bbe8b591472136559041bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
